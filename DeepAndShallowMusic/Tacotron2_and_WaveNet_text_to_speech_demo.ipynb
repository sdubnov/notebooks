{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "syjMmwOEa-uk"
   },
   "source": [
    "# Text-to-speech demo\n",
    "\n",
    "- Tacotron2 (mel-spectrogram prediction part): https://github.com/Rayhane-mamah/Tacotron-2\n",
    "- WaveNet: https://github.com/r9y9/wavenet_vocoder\n",
    "\n",
    "This is a proof of concept for Tacotron2 text-to-speech synthesis. Models used here were trained on [LJSpeech dataset](https://keithito.com/LJ-Speech-Dataset/).\n",
    "\n",
    "**Notice**: The waveform generation is super slow since it implements naive autoregressive generation. It doesn't use parallel generation method described in [Parallel WaveNet](https://arxiv.org/abs/1711.10433). \n",
    "\n",
    "**Estimated time to complete**: 2 ~ 3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NlLC7Q7Us8go"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists, join, expanduser\n",
    "\n",
    "os.chdir(expanduser(\"~\"))\n",
    "\n",
    "wavenet_dir = \"wavenet_vocoder\"\n",
    "if not exists(wavenet_dir):\n",
    "  ! git clone https://github.com/r9y9/$wavenet_dir\n",
    "    \n",
    "taco2_dir = \"Tacotron-2\"\n",
    "if not exists(taco2_dir):\n",
    "  ! git clone https://github.com/r9y9/$taco2_dir\n",
    "  ! cd $taco2_dir && git checkout -B wavenet3 origin/wavenet3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7R_1MpFc3Za"
   },
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBFfji_Avluz"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "! pip install -q --upgrade \"tensorflow<=1.9.0\"\n",
    "! pip install librosa\n",
    "! pip install lws\n",
    "os.chdir(join(expanduser(\"~\"), taco2_dir))\n",
    "! pip install -q -r requirements.txt\n",
    "\n",
    "os.chdir(join(expanduser(\"~\"), wavenet_dir))\n",
    "! pip install -q -e '.[train]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15p8phXx6nxe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fZo1X7ac_Tp"
   },
   "source": [
    "### Download pretrained models\n",
    "\n",
    "#### Tacotron2 (mel-spectrogram prediction part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sau06KhizkoD"
   },
   "outputs": [],
   "source": [
    "os.chdir(join(expanduser(\"~\"), taco2_dir))\n",
    "! mkdir -p logs-Tacotron\n",
    "if not exists(\"logs-Tacotron/pretrained\"):\n",
    "  ! curl -O -L \"https://www.dropbox.com/s/vx7y4qqs732sqgg/pretrained.tar.gz\"\n",
    "  ! tar xzvf pretrained.tar.gz\n",
    "  ! mv pretrained logs-Tacotron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4tWl_hfdXdh"
   },
   "source": [
    "#### WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q2kwJ-t_ykXZ"
   },
   "outputs": [],
   "source": [
    "os.chdir(join(expanduser(\"~\"), wavenet_dir))\n",
    "wn_preset = \"20180510_mixture_lj_checkpoint_step000320000_ema.json\"\n",
    "wn_checkpoint_path = \"20180510_mixture_lj_checkpoint_step000320000_ema.pth\"\n",
    "\n",
    "if not exists(wn_preset):\n",
    "  !curl -O -L \"https://www.dropbox.com/s/0vsd7973w20eskz/20180510_mixture_lj_checkpoint_step000320000_ema.json\"\n",
    "if not exists(wn_checkpoint_path):\n",
    "  !curl -O -L \"https://www.dropbox.com/s/zdbfprugbagfp2w/20180510_mixture_lj_checkpoint_step000320000_ema.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "km1SAASEcIL6"
   },
   "source": [
    "## Input texts to be synthesized\n",
    "\n",
    "Choose your favorite sentences :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LeTMHHFdcmS"
   },
   "outputs": [],
   "source": [
    "os.chdir(join(expanduser(\"~\"), taco2_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tU1lz6PcbXut"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << EOS > text_list.txt\n",
    "I cannot believe that we have end to end text to speech setup.\n",
    "This is really awesome!\n",
    "This is text-to-speech online demonstration by Tacotron 2, Mel Super Resolution and Wavenet.\n",
    "Thanks for your patience.\n",
    "EOS\n",
    "\n",
    "cat text_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9akhzMhbWe0"
   },
   "source": [
    "## Mel-spectrogram prediction by Tacoron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0n4h5aa51dHS"
   },
   "outputs": [],
   "source": [
    "# Remove old files if exist\n",
    "! rm -rf tacotron_output\n",
    "! python synthesize.py --model='Tacotron' --mode='eval' \\\n",
    "  --hparams='symmetric_mels=False,max_abs_value=4.0,power=1.1,outputs_per_step=1' \\\n",
    "  --text_list=./text_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-b4NK7grkrh"
   },
   "source": [
    "# Spectrogram Inversion by MelSrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ayw1c5zKLY_"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import lws\n",
    "\n",
    "def create_mel_filterbank(*args, **kwargs):\n",
    "  return librosa.filters.mel(*args, **kwargs)\n",
    "\n",
    "def create_inverse_mel_filterbank(*args, **kwargs):\n",
    "  W = create_mel_filterbank(*args, **kwargs)\n",
    "  return np.linalg.pinv(W)\n",
    "\n",
    "class SpectralUtil(object):\n",
    "  NFFT = 1024\n",
    "  NHOP = 256\n",
    "  FMIN = 125.\n",
    "  FMAX = 7600.\n",
    "  NMELS = 80\n",
    "  fs = 22050\n",
    "\n",
    "  def __init__(self):\n",
    "    meltrans = create_mel_filterbank(\n",
    "            self.fs, self.NFFT, fmin=self.FMIN, fmax=self.FMAX, n_mels=self.NMELS)\n",
    "    invmeltrans = create_inverse_mel_filterbank(\n",
    "            self.fs, self.NFFT, fmin=self.FMIN, fmax=self.FMAX, n_mels=self.NMELS)\n",
    "\n",
    "    self.meltrans = tf.constant(meltrans, dtype = 'float32')\n",
    "    self.invmeltrans = tf.constant(invmeltrans, dtype = 'float32')\n",
    "    self.invmeltrans_np = invmeltrans\n",
    "    self.meltrans_np = meltrans\n",
    "    self.lws_processor = lws.lws(self.NFFT, self.NHOP, mode='speech', perfectrec=False)\n",
    "\n",
    "  def mag_to_mel_linear_spec(self, mag_spec):\n",
    "    linear_mel =  tf.expand_dims(\n",
    "      tf.tensordot(mag_spec[:,:,:,0], tf.transpose(self.meltrans), axes = 1 ), -1)\n",
    "    return linear_mel\n",
    "\n",
    "  def mel_linear_to_mag_spec(self, mel_spec, transform = 'inverse'):\n",
    "    if transform == 'inverse':\n",
    "      transform_mat = tf.transpose(self.invmeltrans)\n",
    "    elif transform == 'transposed':\n",
    "      transform_mat = meltrans\n",
    "    else:\n",
    "      raise NotImplementedError()\n",
    "    mag_spec =  tf.expand_dims(\n",
    "      tf.tensordot(mel_spec[:,:,:,0], transform_mat, axes = 1 ), -1)\n",
    "    return mag_spec\n",
    "\n",
    "  def audio_from_mag_spec(self, mag_spec):\n",
    "    mag_spec = mag_spec.astype('float64')\n",
    "    spec_lws = self.lws_processor.run_lws(mag_spec[:,:,0])\n",
    "    magspec_inv = self.lws_processor.istft(spec_lws)[:, np.newaxis, np.newaxis]\n",
    "    magspec_inv = magspec_inv.astype('float32')\n",
    "    return magspec_inv\n",
    "  \n",
    "  def tacotron_mel_to_mag(self, tacotron_mel):\n",
    "    norm_min_level_db = -100\n",
    "    norm_ref_level_db = 20\n",
    "    nfft = 1024\n",
    "    nhop = 256\n",
    "    mel_min = 125\n",
    "    mel_max = 7600\n",
    "    mel_num_bins = 80\n",
    "    fs = 22050\n",
    "    \n",
    "    X_mel_dbnorm = np.interp(tacotron_mel, (0, 4), (0, 1))\n",
    "    X_mel_db = (X_mel_dbnorm * -norm_min_level_db) + norm_min_level_db\n",
    "    X_mel = np.power(10, (X_mel_db + norm_ref_level_db) / 20)\n",
    "    X_mag = np.dot(X_mel, self.invmeltrans_np.T)\n",
    "    \n",
    "    return X_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrLDTehPH4L4"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import tensorflow as tf\n",
    "os.chdir(expanduser(\"~\"))\n",
    "vocoder_ckpt_dir = join(expanduser(\"~\"), \"srezvocodercpts\")\n",
    "if not os.path.isdir(vocoder_ckpt_dir):\n",
    "  os.makedirs(vocoder_ckpt_dir)\n",
    "  os.chdir(vocoder_ckpt_dir)\n",
    "  ! wget deepyeti.ucsd.edu/paarth/srezvocoderckpts/best_gen_loss_l1-50001.index;\n",
    "  ! wget deepyeti.ucsd.edu/paarth/srezvocoderckpts/best_gen_loss_l1-50001.meta;\n",
    "  ! wget deepyeti.ucsd.edu/paarth/srezvocoderckpts/best_gen_loss_l1-50001.data-00000-of-00001\n",
    "\n",
    "os.chdir(expanduser(\"~\"))\n",
    "gen_graph = tf.Graph()\n",
    "with gen_graph.as_default():\n",
    "  gan_saver = tf.train.import_meta_graph(join(expanduser(\"~\"), \"srezvocodercpts/best_gen_loss_l1-50001.meta\"))\n",
    "gen_sess = tf.Session(graph=gen_graph)\n",
    "print(\"Restoring\")\n",
    "gan_saver.restore(gen_sess, join(expanduser(\"~\"), \"srezvocodercpts/best_gen_loss_l1-50001\"))\n",
    "gen_mag_spec = gen_graph.get_tensor_by_name('generator/decoder_1/strided_slice_1:0')\n",
    "x_mag_input = gen_graph.get_tensor_by_name('ExpandDims_1:0')\n",
    "\n",
    "su = SpectralUtil()\n",
    "\n",
    "with open(\"Tacotron-2/tacotron_output/eval/map.txt\") as f:\n",
    "  maps = f.readlines()\n",
    "maps = list(map(lambda x:x[:-1].split(\"|\"), maps))\n",
    "# filter out invalid ones\n",
    "maps = list(filter(lambda x:len(x) == 2, maps))\n",
    "\n",
    "print(\"List of texts to be synthesized\")\n",
    "for idx, (text,_) in enumerate(maps):\n",
    "  print(idx, text)\n",
    "\n",
    "for idx, (text, mel) in enumerate(maps):\n",
    "  mel_path = join(\"Tacotron-2\", mel)\n",
    "  c = np.load(mel_path)\n",
    "  \n",
    "  X_mag = su.tacotron_mel_to_mag(c)\n",
    "  x_mag_target_length = int(X_mag.shape[0] / 64 ) * 64 + 64\n",
    "  X_mag = np.pad(X_mag, ([0,x_mag_target_length - X_mag.shape[0]], [0,0]), 'constant')\n",
    "  num_examples = int(x_mag_target_length/64)\n",
    "  X_mag = np.reshape(X_mag, [num_examples, 64, 513, 1])\n",
    "  \n",
    "  gen_mags = []\n",
    "  heuristic_mags = []\n",
    "  for n in range(num_examples):\n",
    "    _gen, _heur = gen_sess.run([gen_mag_spec, x_mag_input], feed_dict = {\n",
    "        x_mag_input : X_mag[n:n+1]\n",
    "        })\n",
    "    gen_mags.append(_gen[0])\n",
    "    heuristic_mags.append(_heur[0])\n",
    "  \n",
    "  gen_mag = np.concatenate(gen_mags, axis = 0)\n",
    "  heur_mag = np.concatenate(heuristic_mags, axis = 0)\n",
    "  \n",
    "  _gen_audio = su.audio_from_mag_spec(gen_mag)\n",
    "  _heur_audio = su.audio_from_mag_spec(heur_mag)\n",
    "  print(idx, text)\n",
    "  print(\"generated melsrez\")\n",
    "  IPython.display.display(Audio(_gen_audio[:,0,0], rate=22050))\n",
    "  print(\"heuristic inversion\")\n",
    "  IPython.display.display(Audio(_heur_audio[:,0,0], rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FF1mh1Jvdp0a"
   },
   "source": [
    "## Waveform synthesis by WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY_MfE0m8Ese"
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTmp0T0G3lU0"
   },
   "outputs": [],
   "source": [
    "os.chdir(join(expanduser(\"~\"), wavenet_dir))\n",
    "\n",
    "# Setup WaveNet vocoder hparams\n",
    "from hparams import hparams\n",
    "with open(wn_preset) as f:\n",
    "    hparams.parse_json(f.read())\n",
    "\n",
    "# Setup WaveNet vocoder\n",
    "from train import build_model\n",
    "from synthesis import wavegen\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "model = build_model().to(device)\n",
    "\n",
    "print(\"Load checkpoint from {}\".format(wn_checkpoint_path))\n",
    "checkpoint = torch.load(wn_checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "334X6oFK6Vf9"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"../Tacotron-2/tacotron_output/eval/map.txt\") as f:\n",
    "  maps = f.readlines()\n",
    "maps = list(map(lambda x:x[:-1].split(\"|\"), maps))\n",
    "# filter out invalid ones\n",
    "maps = list(filter(lambda x:len(x) == 2, maps))\n",
    "\n",
    "print(\"List of texts to be synthesized\")\n",
    "for idx, (text,_) in enumerate(maps):\n",
    "  print(idx, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaleFjoyiND_"
   },
   "source": [
    "### Waveform generation\n",
    "\n",
    "**Note**: This will takes hours to finish depending on the number and lenght of texts. Try short sentences first if you would like to see samples quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9BO7IES7Htp"
   },
   "outputs": [],
   "source": [
    "waveforms = []\n",
    "\n",
    "for idx, (text, mel) in enumerate(maps):\n",
    "  print(\"\\n\", idx, text)\n",
    "  mel_path = join(\"../Tacotron-2\", mel)\n",
    "  c = np.load(mel_path)\n",
    "  if c.shape[1] != hparams.num_mels:\n",
    "    np.swapaxes(c, 0, 1)\n",
    "  # Range [0, 4] was used for training Tacotron2 but WaveNet vocoder assumes [0, 1]\n",
    "  c = np.interp(c, (0, 4), (0, 1))\n",
    " \n",
    "  # Generate\n",
    "  waveform = wavegen(model, c=c, fast=True, tqdm=tqdm)\n",
    "  \n",
    "  waveforms.append(waveform)\n",
    "\n",
    "  # Audio\n",
    "  IPython.display.display(Audio(waveform, rate=hparams.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNG8oI4OiJkJ"
   },
   "source": [
    "## Summary: audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIyfhn0v9Ntg"
   },
   "outputs": [],
   "source": [
    "for idx, (text, mel) in enumerate(maps):\n",
    "  print(idx, text)\n",
    "  IPython.display.display(Audio(waveforms[idx], rate=hparams.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0hc4ah-gMUa"
   },
   "source": [
    "For more information, please visit https://github.com/r9y9/wavenet_vocoder. More samples can  be  found at https://r9y9.github.io/wavenet_vocoder/. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Tacotron2 and WaveNet  text-to-speech demo.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
